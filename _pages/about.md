---
layout: about
title: about
permalink: /
subtitle: Graduate Student @ <a href="https://www.psu.edu/">PennState</a> 

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 3 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I'm a third-year graduate student at [The Pennsylvania State University](https://www.psu.edu/), pursuing a Ph.D. in Computer Science and Engineering under the guidance of Prof. [Vijaykrishnan Narayanan](https://sites.psu.edu/vijaykrishnannarayanan/).


Before my graduate studies, I was a software engineer at [Navis](https://www.navis.com) for two years (2020–2022), where I helped design and build scalable machine learning platforms for predictive and prescriptive analytics in global shipping terminal operations. My work involved developing data pipelines and streaming services using Apache Kafka to support real-time analytics and model deployment. I completed my Bachelor's in Computer Engineering (Honors, specialization in AI & ML) from the Indian Institute of Information Technology, Design and Manufacturing, Kancheepuram ([IIITDM Kancheepuram](http://www.iiitdm.ac.in)) in 2020.

Outside of research, I enjoy cycling, working out, and experimenting with creative accessibility technologies in my spare time.

## research focus

My research focuses on human-centered and multimodal AI, spanning visual accessibility, AR-based interaction, and efficient large-model systems. I am currently working on developing AI and AR-powered assistive systems that help blind and low-vision users find and interact with objects in their environment using LiDAR-equipped iPhones, ARKit, and vision-language models (VLMs/LLMs). This line of work, supported by the National Science Foundation (Grant No. 2318101), explores how multimodal and generative AI can enhance independence and accessibility for people with disabilities.

I am also interested in model optimization and adaptive inference, including multi-armed bandit–based routing for large language models to improve efficiency and responsiveness. Broadly, my interests lie in computer vision, agentic AI, model optimization, and machine learning systems for accessibility and inclusion.
