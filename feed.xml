<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ajaynarayanan.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ajaynarayanan.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-28T02:06:08+00:00</updated><id>https://ajaynarayanan.github.io/feed.xml</id><title type="html">Ajay Narayanan Sridhar</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">AI for insect detection &amp;amp; classification</title><link href="https://ajaynarayanan.github.io/blog/2025/insect-detection/" rel="alternate" type="text/html" title="AI for insect detection &amp;amp; classification"/><published>2025-04-27T00:00:00+00:00</published><updated>2025-04-27T00:00:00+00:00</updated><id>https://ajaynarayanan.github.io/blog/2025/insect-detection</id><content type="html" xml:base="https://ajaynarayanan.github.io/blog/2025/insect-detection/"><![CDATA[<p>After conducting the <a href="https://insectnet.psu.edu/student-resources/sp25-virtual-workshop-ai-for-insect-detection-classification">AI for Insect Detection &amp; Classification Workshop</a><d-cite key="insectnetworkshop2025"></d-cite> at The Pennsylvania State University, I felt motivated to share some of the key ideas more widely.</p> <p>This blog post is designed for readers with little to no coding experience. The goal is to explain how simple motion detection and modern object detection models like YOLO<d-cite key="redmon2016you"></d-cite> can be used to monitor insects ‚Äî using visuals and plain language, without diving into heavy math or programming details. Images and videos used in the blog are obtained from the InsectEye<d-cite key="homan2023insecteye"></d-cite> system.</p> <p>I hope you find this exploration both accessible and interesting!</p> <h2 id="introduction">Introduction</h2> <p>Step into a field at dawn, and you‚Äôll hear a quiet symphony of tiny wings.<br/> Some belong to helpful pollinators üêù, while others are hungry pests üêõ.</p> <p>Catching these insects early can protect crops, reduce chemical sprays, and help us understand how seasons and climate shape insect life. But how do you do that without draining batteries or overwhelming tiny edge devices?</p> <p>We use a <strong>two-step camera system</strong> that‚Äôs smart and simple:</p> <ol> <li><strong>Notice insect motion</strong> ‚Äî ‚ÄúSomething moved.‚Äù</li> <li><strong>Detect pests with YOLO</strong> ‚Äî ‚ÄúWhich insect is it?‚Äù</li> </ol> <p>Let‚Äôs dive into how motion spotting and fast object detection help keep a watchful eye on the fields ‚Äî one tiny wingbeat at a time.</p> <hr/> <h2 id="motion-detection-for-insects">Motion detection for insects</h2> <div class="col-sm mt-3 mt-md-0 text-center"> <img src="/assets/blogs/insect_detection/motion_detection/insect.gif" class="img-fluid rounded z-depth-1" style="transform: rotate(180deg); margin-bottom: 20px;" alt="Insect GIF"/> <br/> <img src="/assets/blogs/insect_detection/motion_detection/motion_masks.gif" class="img-fluid rounded z-depth-1" style="transform: rotate(180deg);" alt="Motion Mask GIF"/> </div> <div class="caption mt-2 text-center"> Fig. 1: Animated GIFs showing the insect video sequence (top) and the corresponding motion masks (bottom). </div> <p>When a camera sits still, most of the scene stays the same. If a handful of pixels suddenly change, that signals <strong>motion</strong>. Here‚Äôs a simple background subtraction method to pick out moving insects:</p> <ol> <li> <strong>Build a background model</strong><br/> Watch the scene for a few seconds with no insects, then average those frames to create a ‚Äòclean‚Äô background image. Alternatively, use a single snapshot without any bugs. <div class="text-center my-2" style="line-height: 0;"> <img src="/assets/blogs/insect_detection/motion_detection/background_image.png" class="img-fluid rounded z-depth-1" style="transform: rotate(180deg); display: block; margin: 20 auto;" alt="Background Image"/> <div class="caption text-center" style="margin-top: 20px; font-size: 0.9rem;"> Fig. 2: Background model for our video sequence. </div> </div> </li> <li> <strong>Frame difference</strong><br/> <ul style="margin-top: 0.5rem; margin-bottom: 0;"> <li>Subtract the background model from the current frame to get a difference image.</li> <li>Large pixel differences usually mean motion.</li> <li>Threshold the difference image into a black-and-white motion mask (white = moving pixels; black = background).</li> </ul> </li> </ol> <div class="col-sm mt-3 mt-md-0 text-center"> <div style="background: white; padding: 10px; display: inline-block; border-radius: 8px;"> <img src="/assets/blogs/insect_detection/motion_detection/motion_detection_mask.png" class="img-fluid rounded" style="margin-bottom: 20px;" alt="Motion Detection Mask"/> </div> </div> <div class="caption mt-2 text-center"> Fig. 3: Difference mask obtained by subtracting the current frame from the background and then thresholding. </div> <p>Motion detection is all around us. Here are a few real-world examples:</p> <ul style="margin-top: 0.5rem; margin-bottom: 0;"> <li>Security cameras &amp; intrusion alarms</li> <li>Sports highlights</li> <li>Wildlife monitoring (trail cams)</li> <li>Traffic flow analysis</li> </ul> <hr/> <h2 id="insect-detection-with-yolo">Insect detection with YOLO</h2> <p>Motion detection points out <em>where</em> to look, and <strong>YOLO</strong> tells us <em>what</em> is moving. YOLO<d-cite key="redmon2016you"></d-cite> is an object detection model that draws boxes around objects and labels them. We use YOLO for insects because:</p> <ul> <li><strong>Real-time:</strong> Runs at video speed, even on small devices.</li> <li><strong>All-in-one:</strong> Finds both location and the insect‚Äôs identity in a single pass.</li> <li><strong>Open-source:</strong> Free models (YOLOv8) and easy training tools are available.</li> </ul> <p>We now describe the original version of YOLO. Although many improvements have been made across subsequent versions, the core ideas outlined below remain the same.</p> <h3 id="the-quick-yolo-tour">The quick YOLO tour</h3> <ol> <li> <strong>Candidate frames</strong><br/> <em>After motion detection, we extract snapshots that might contain insects.</em> <div class="text-center"> <img src="/assets/blogs/insect_detection/yolo_steps/input_image.jpg" alt="Input Image" class="img-fluid rounded"/> <div class="caption mt-2 text-center"> Fig. 4: Input image for insect detection, obtained from motion detection. </div> </div> </li> <li> <strong>Resize &amp; grid</strong><br/> <em>Resize each snapshot to 448√ó448 pixels and overlay a 7√ó7 grid.</em> <div class="text-center"> <img src="/assets/blogs/insect_detection/yolo_steps/cropped_grid_image.png" alt="Cropped and 7x7 grid overlayed image" class="img-fluid rounded"/> <div class="caption mt-2 text-center"> Fig. 5: A 7√ó7 grid overlaid on the cropped image. </div> </div> </li> <li> <strong>One glance, many predictions</strong><br/> <em>For each grid cell, YOLO‚Äôs neural network predicts several bounding boxes, confidence scores, and class probabilities for different insects.</em> <div class="text-center"> <img src="/assets/blogs/insect_detection/yolo_steps/grid_cell_prediction.png" alt="YOLO grid cell predictions" class="img-fluid rounded"/> <div class="caption mt-2 text-center"> Fig. 6: The green box has a high confidence score and class probability; the red boxes are low confidence. </div> </div> </li> <li> <strong>Keep the best</strong><br/> <em>Non-Maximum Suppression (NMS)<d-cite key="hosang2017learning"></d-cite> keeps the highest-scoring box and removes overlapping, lower-scoring ones.</em> <div class="text-center"> <img src="/assets/blogs/insect_detection/yolo_steps/non_maximum_suppression.png" alt="Non Maximum Suppression process" class="img-fluid rounded"/> <div class="caption mt-2 text-center"> Fig. 7: NMS removes duplicate boxes, leaving one clear box per object. </div> </div> <p class="mt-2"> After predicting many boxes, NMS: </p> <ul style="margin-top: 0.5rem; margin-bottom: 0;"> <li>Keeps the box with the highest confidence score.</li> <li>Removes boxes that overlap too much (measured by Intersection over Union, or IoU).</li> </ul> <p> This leaves one clean box per insect. In our diagram, the green box remains and the yellow ones are discarded. </p> </li> <li> <strong>Final output</strong><br/> <em>We get the insect‚Äôs class, a confidence score, and the bounding box coordinates.</em> </li> </ol> <p>You might be wondering:</p> <ol> <li> <strong>How are the bounding boxes represented?</strong> <div class="text-center"> <div style="background: white; padding: 10px; display: inline-block; border-radius: 8px;"> <img src="/assets/blogs/insect_detection/yolo_steps/bounding_box_representation.png" alt="Bounding box representation" class="img-fluid rounded"/> </div> <div class="caption mt-2 text-center"> Fig. 8: Bounding box representation. </div> </div> <ul style="margin-top: 0.5rem; margin-bottom: 0;"> <li>Each box is defined by (cx, cy, w, h).</li> <li>(cx, cy) is the box center, normalized within its grid cell.</li> <li>(w, h) is the width and height, relative to the full image.</li> </ul> </li> <li> <strong>What if the insect overlaps two grid cells?</strong> <div class="text-center"> <img src="/assets/blogs/insect_detection/yolo_steps/overlapping_grid_cells.png" alt="Overlapping grid cells" class="img-fluid rounded"/> <div class="caption mt-2 text-center"> Fig. 9: Handling overlapping grid cells. </div> </div> <ul style="margin-top: 10px;"> <li>Only the cell (marked as 1) containing the insect‚Äôs center (marked by a star) makes the prediction.</li> <li>Neighboring cells ignore this insect and focus on objects whose centers lie inside them.</li> </ul> </li> </ol> <hr/> <h2 id="conclusion--next-steps">Conclusion &amp; next steps</h2> <p>Combining <strong>motion detection</strong> with <strong>YOLO</strong> creates a nimble tag-team. On a 90,000-frame video, motion detection trimmed the candidates down to just 1,000 frames. This shows why pairing motion and object detection is essential for bio-monitoring systems that run on tight compute and energy budgets.</p> <p>Next on our roadmap:</p> <ul> <li><strong>See even smaller bugs</strong> ‚Äî add a zoom lens or train YOLO with clearer close-ups.</li> <li><strong>Dashboards for farmers</strong> ‚Äî stream live counts to a phone app for same-day action.</li> </ul> <p>Have ideas, questions, or cool bug clips? Drop a comment below ‚Äî we‚Äôd love to chat! ü™≤üëã</p>]]></content><author><name></name></author><category term="computer-vision,"/><category term="deep-learning,"/><category term="insects,"/><category term="education"/><summary type="html"><![CDATA[A simple, visual walkthrough of how AI can spot and identify insects using motion detection and YOLO.]]></summary></entry></feed>